{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmyiRUaz/pt6BAqqeuMu/l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabiankmroh/llm-application/blob/main/embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch"
      ],
      "metadata": {
        "id": "l6oNrnz0HH2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tokenize.py\n",
        "# Separate by Spaces\n",
        "input_text = \"I have been on a trip to Paris recently.\"\n",
        "input_text_list = input_text.split()\n",
        "print(\"input_text_list: \", input_text_list)\n",
        "\n",
        "# Token --> ID Dictionary & ID --> Token Dictionary\n",
        "str2idx = {word:idx for idx, word in enumerate(input_text_list)}\n",
        "idx2str = {idx:word for idx, word in enumerate(input_text_list)}\n",
        "print(str2idx)\n",
        "print(idx2str)\n",
        "\n",
        "input_ids = [str2idx[word] for word in input_text_list]\n",
        "print(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcwNimesHqCd",
        "outputId": "c41158c2-479c-40d3-a71f-5399650a255d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_text_list:  ['I', 'have', 'been', 'on', 'a', 'trip', 'to', 'Paris', 'recently.']\n",
            "{'I': 0, 'have': 1, 'been': 2, 'on': 3, 'a': 4, 'trip': 5, 'to': 6, 'Paris': 7, 'recently.': 8}\n",
            "{0: 'I', 1: 'have', 2: 'been', 3: 'on', 4: 'a', 5: 'trip', 6: 'to', 7: 'Paris', 8: 'recently.'}\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imNOVguJG2Tm"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 16 # Intuition on Dimensions of Embedding?\n",
        "embed_layer = nn.Embedding(len(str2idx), embedding_dim) # Define a Func w/ nn.Embedding\n",
        "\n",
        "input_embeddings = embed_layer(torch.tensor(input_ids)) # Tensors?\n",
        "input_embeddings = input_embeddings.unsqueeze(0) # Unsqueeze? Dimension Changes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings.shape"
      ],
      "metadata": {
        "id": "Y7f5D7XBJJCF",
        "outputId": "9de3c7a9-c1db-43c8-db4c-f62f5d6c6997",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 9, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Absolute Position Encoding\n",
        "embedding_dim = 16\n",
        "max_position = 12\n",
        "\n",
        "embed_layer = nn.Embedding(len(str2idx), embedding_dim)\n",
        "position_embed_layer = nn.Embedding(max_position, embedding_dim)\n",
        "\n",
        "position_ids = torch.arange(len(input_ids), dtype = torch.long).unsqueeze(0)\n",
        "position_encodings = position_embed_layer(position_ids)\n",
        "\n",
        "token_embeddings = embed_layer(torch.tensor(input_ids))\n",
        "token_embeddings = token_embeddings.unsqueeze(0)\n",
        "\n",
        "input_embeddings = token_embeddings + position_encodings"
      ],
      "metadata": {
        "id": "Lg_VC2D9JJ_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX7LP48Egrzb",
        "outputId": "50bde351-256f-4f50-8271-e28b4653d2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 9, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sNJ-63_HhOAD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}